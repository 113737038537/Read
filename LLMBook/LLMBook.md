# 第1部分 背景与基础知识

## 第1章 引言

### 1.1 语言模型的发展历程

四个发展阶段：

* 统计语言模型（Statistical Language Model,SLM）
* 神经语言模型（Neural Language Model，NLM）e.g.,RNN
* 预训练语言模型（Pre-trained Language Model，PLM）
  * 基于Self-Attention的Transformer模型
  * e.g.，ELMO、BERT、GPT-1
* 大语言模型（Large Language Model，LLM）
  * 大规模的预训练语言模型

### 1.2  大语言模型的能力特点

* 经过超大规模文本数据的预训练后能够学习到较为丰富的世界知识
* 较强的通用任务解决能力
* 较好的复杂任务推理能力
* 较强的人类指令遵循能力
* 较好的人类对齐能力
* 可拓展工具使用能力

### 1.3 大语言模型关键技术概览

* 规模拓展（Scaling Law）
  * 从参数、数据、算力三个方面深入地研究了规模扩展对于模型性能所带来的影响，建立了定量的函数关系
* 数据工程
  * 全面采集
  * 数据清洗
  * 数据配比
* 高效预训练
  * 大规模分布式训练
  * 3D并行（数据、流水线、张量）
  * ZeRO（内存冗余消除技术）
* 人类对齐
  * 3H:Helpfulness,Honesty,Harmlessness
* 工具使用

### 1.4 大语言模型对科技发展的影响

* 自然语言处理
* 信息检索
* 计算机视觉
* 人工智能赋能的科学研究

### 1.5 本书内容介绍

**五个部分：**

* 背景与基础知识
  * 第2章 介绍大语言模型的构建过程
    * 涌现能力，拓展定律
  * 第3章 大语言模型的相关资源信息
    * 模型检查点和API、数据集、代码
* 预训练部分
  * 第4章 预训练数据的准备工作
    * 数据收集、清洗、词元化
  * 第5章 大语言模型架构
    * Transformer、配置、长文本建模
  * 第6章 预训练任务
* 逻辑与对齐部分
  * 第7章 指令微调
    * 数据构建、优化策略、轻量化微调、实战示例
  * 第8章 人类对齐技术
    * RLHF、非强化学习对齐方法、SFT与RLHF关系
* 大模型使用部分
  * 第9章 解码与部署
    * 解码策略、加速算法、低资源部署、模型压缩方法
  * 第10章 提示学习技术
    * 提示设计、上下文学习、思维链方法
  * 第11章 复杂任务规划
    * 任务分解、回溯与反思、智能体与多智能体系统
* 评测与应用部分
  * 第12章 性能评测
    * 评测集合、评测指标、评测方法、存在问题
  * 第13章 应用情况
    * 研究领域与应用领域的特化方法
  * 第14章 总结
    * 技术挑战与研究趋势



## 第2章 大语言模型介绍

### 2.1 大语言模型的构建过程

大语言模型需要两种训练方法：

* 大规模预训练
* 指令微调和人类对齐

#### 2.1.1 大规模预训练

由于 GPT 系列模型的爆火，“解码器架构 + 预测下一个词”的有效性得到了充分验证，已经成为现有大语言模型主要采纳的技术路径。

预训练的两个前提：

* 数据清洗
* 算力资源

#### 2.1.2 指令微调与人类对齐

**下游任务（DownStream Task）**

> "下游任务"（Downstream Task）是机器学习和自然语言处理（NLP）领域的一个术语，特指在预训练模型的基础上进行的特定任务。这些任务是在模型已经通过大量通用数据进行预训练并学习了语言的基本规律和表示后，为了让模型能够更好地应用于特定领域或解决特定问题而进行的。
>
> 下游任务的例子包括但不限于：
>
> - 文本分类：如情感分析，判断一段文本的情绪倾向是积极还是消极。
> - 命名实体识别（NER）：从文本中识别出特定的实体，如人名、地名、组织名等。
> - 问答系统：根据给定的问题和背景资料，模型生成或选择正确的答案。
> - 文本摘要：生成一段文本的简短概括。
> - 机器翻译：将一种语言的文本翻译成另一种语言。
>
> 预训练模型通过在大量的、多样化的数据上学习，获得了对语言的广泛理解。然后，通过在特定的下游任务上进行微调（fine-tuning），模型可以将这种广泛的语言理解能力应用于具体任务，从而在该任务上表现得更好。这种方法的优势在于，预训练阶段提供了一个强大的通用基础，而微调阶段则允许模型针对特定任务进行优化。

**指令微调（有监督微调，Supervised Fine-tuning,SFT）**

> 通过使用任务输入与输出的配对数据进行模型训练，可以使得语言模型较好地掌握通过问答形式进行任务求解的能力。本质上是机器学习中的模仿学习。

* 主要起到对于模型的激发作用，而不是知识注入作用。
* 需要的数据量较小，十万到百万规模的数据量
  * 甚至千条到万条的高质量指令数据就能达到不错的效果
* 需要的算力资源较小

**基于人类反馈的强化学习对齐方法RLHF（Reinforcement Learning from Human Feedback）**

* 训练一个符合人类价值观的奖励模型

### 2.2 扩展法则

#### 2.2.1 KM扩展法则

#### 2.2.2 Chinchilla 扩展法则

#### 2.2.3 关于扩展法则的讨论

* 可预测的扩展
  * 使用小模型的性能去预估大模型的性能
  * 使用大模型的早期训练性能去估计训练完成后的性能
* 任务层面的可预测性
  * 在实践中，我们则更关注大语言模型在真实任务中的性能提升
  * 基础问题：语言建模损失（例如平均交叉熵损失）的减少是否真正意味着（或对应着）真实任务上模型性能的提高

### 2.3 涌现能力

> 当模型扩展到一定规模时，模型的 特定任务性能突然出现显著跃升的趋势，远超过随机水平

#### 2.3.1 代表性的涌现能力

三种典型的涌现能力：

* 上下文学习（In-context Learning,ICL)
  * 在提示中为语言模型提供自然语言指令和多个 任务示例（Demonstration），无需显式的训练或梯度更新，仅输入文本的单词序列 就能为测试样本生成预期的输出
* 指令遵循
* 逐步推理
  * 通过COT提示策略加强推理性能


#### 2.3.2 涌现能力和扩展法则的关系

> 扩展法则使用语言建模损失来衡量语言模 型的整体性能，整体上展现出了较为平滑的性能提升趋势，具有较好的可预测性， 但是指数形式暗示着可能存在的边际效益递减现象；而涌现能力通常使用任务性 能来衡量模型性能，整体上展现出随规模扩展的骤然跃升趋势，不具有可预测性， 但是一旦出现涌现能力则意味着模型性能将会产生大幅跃升。由于这两种观点反 映了不同的模型性能提升趋势（持续改进 v.s. 性能跃升），可能在一些情况下会导 致不一致的发现与结论。

### 2.4 GPT系列模型的技术演变

![image-20240528131044871](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240528131044871.png)

## 第3章 大语言模型资源

### 3.1 公开可用的模型检查点或API

#### 3.1.1 公开可用的通用大语言模型检查点

![image-20240529114654435](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240529114654435.png)

* *LLaMA* 和 *LLaMA-2* 
  Source: Meta AI
* *ChatGLM* 
  Source: 清华 和 智谱AI

* *Falcon* 
  Source: TII (阿布扎比技术创新研究院)

* *Baichuan* 和 *Baichuan-2* 
  Source: 百川智能公司

* *InternLM* 和 *InternLM-2* 
  Source: 上海人工智能实验室

* *Qwen* 
  Source: 阿里巴巴公司

* *Mistral* 
  Source: Mistral AI

* *DeepSeek LLM* 
  Source: 幻方公司

* *Mixtral* 
  Source: Mistral AI

* *Gemma* 
  Source: 谷歌

* *MiniCPM* 
  Source: 面壁智能 和 清华大学

* *YuLan-Chat* 
  Source: 中国人民大学

#### 3.1.2 LLaMA 变体系列

> LLaMA 拥有较优的模型性能，并作为开源模型而方便用户公开获取
>
> 指令微调由于相对较低的计算成本，已成为开发定制化或 专业化模型的首选方法，也因此出现了庞大的 LLaMA 家族

![image-20240528135854838](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240528135854838.png)

#### 3.1.3 大语言模型的公用API

> 目前性能最强大的模型仍然主要以 闭源为主。这些闭源模型通过 API（应用程序接口）形式进行调用，无需在本地运行模型即可使用

* 语言模型API
  * 接口：GPT3.5-Turbo、GPT-4、GPT-4o
  * 使用自己的数据微调模型
    * 提高模型的指令遵循能力、定制化输出格式等
* 文本表征API

### 3.2 常用的预训练数据集

**网页**

* 通用网页数据（主要以英文为主）

![image-20240528160017267](C:\Users\YW\AppData\Roaming\Typora\typora-user-images\image-20240528160017267.png)

**书籍**

**维基百科**

**代码**

**混合型数据集**

### 3.3 微调数据集

两个主要步骤：**指令微调（有监督微调）** 和 **对齐微调**

* 指令微调

![image-20240528171132300](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240528171132300.png)

* 对齐微调

![image-20240528171255245](C:\Users\YW\AppData\Roaming\Typora\typora-user-images\image-20240528171255245.png)

### 3.4 代码库资源

* Hugging Face开源社区
* DeepSpeed
* Megatron-LM

# 第2部分 预训练

## 第4章 数据准备

### 4.1 数据来源

* 通用文本数据集
  * 网页、书籍和对话文本
* 专用文本数据集
  * 多语数据、科学数据和代码数据

### 4.2 数据预处理

![image-20240528172917011](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240528172917011.png)

#### 4.2.1 质量过滤

两种数据清洗方法：

- 基于启发式规则的方法
  - 基于语种的过滤
    - 为了训练特定目标语言为主导的大语言模型，通常要过滤 掉其他语言的文本数据
  - 基于简单统计指标的过滤
    - 使用语料中标点符号分布、符号与单词比率、句子长度等特征来衡量文本质量，过滤低质量数据
  - 基于关键词的过滤
    - 例如：针对网页数据，过滤掉 HTML 标签
- 基于分类器的方法
  - 训练用于判别数据质量的文本分类器，进行预训练语料的清洗
  - 轻量级模型*FastText*，可微调的预训练模型*BERT,LLAMA*，闭源大语言模型API

#### 4.2.2 敏感内容过滤

* 过滤有毒内容
  * 构建出高效的毒性文本分类器
* 过滤隐私内容
  * 使用启发式方法，如关键字识别

#### 4.2.3 数据去重

- 计算粒度
  - 现有方法主要依靠单词或 𝑛 元词组的重叠这类表层特征，来衡量文档的重叠比率
  - 用于去重的匹配方法

#### 4.2.4 数据对预训练效果的影响

- 数据数量的影响
  - 早期KM法则认为模型参数数量更重要，近期Chinchilla则发现数据数量同样关键
  - 数据量的扩展性本质上来源于 Transformer 模型的可扩展性
- 数据质量的影响
  - 重复数据
    - 可能导致可能导致“双下降现象”，即模型训练损失先经历下降然后出现升高再下降的现象
    - 降低大语言模型利用上下文中信息的能力
  - 有偏、有毒、隐私内容
    - 包含有毒内容，模型则可能会产生侮辱性、攻击性或其他有害的输出
    - 在含有隐私内容的数据上训练可能会导致模型在输出 中无意中泄露或利用个人数据

- 数据集污染
  - 进行模型评测时，可能会发现某些评估基准所包含的数据，实际上已出现在预训练数据或者微调数据中，这种现象被称为基准泄漏或数据集污染
  - 使用评估基准时，应该特别关注预训练数据与训练和测试集之间可能的数据重叠情况

#### 4.2.5 数据集预处理实践

### 4.3 词元化（分词）

#### **编码的基本概念**

1. **Unicode编码**：
   - Unicode是一个国际标准，旨在为世界上所有的字符和符号提供一个唯一的数字标识（称为代码点）。Unicode定义了字符的集合和它们对应的代码点，但它本身不规定如何将这些代码点存储在计算机中。
   - Unicode解决了不同语言和字符集之间的兼容问题，使得不同语言的文本可以在同一个文档或程序中共存。
2. **UTF-8**：
   - UTF-8（8-bit Unicode Transformation Format）是Unicode的一种实现方式，用于在计算机中存储和传输Unicode字符。它是一种可变长度的编码方案，使用1到4个字节来表示一个Unicode代码点。
   - UTF-8的设计允许它与传统的ASCII编码兼容，意味着ASCII编码的文本也是有效的UTF-8编码的文本。这使得UTF-8在互联网和多种计算环境中变得非常流行。

> 代码点本身并不是计算机内存中存储的二进制形式。代码点是Unicode标准中用于抽象地表示每个字符的唯一数字。这些代码点需要通过某种编码方案（如UTF-8、UTF-16或UTF-32）转换成二进制形式，才能在计算机系统中存储和处理。
>
> 例如，Unicode标准可能会将字母"A"分配一个代码点U+0041，但这个代码点本身不是存储在计算机内的形式。在UTF-8编码方案中，这个代码点会被编码成二进制的01000001，这才是计算机内存中存储的实际二进制序列。不同的编码方案会以不同的方式将代码点转换为二进制数据。

#### Tokenization

> 词元化（Tokenization）是数据预处理中的一个关键步骤，旨在将原始文本分割成模型可识别和建模的词元序列，作为大语言模型的输入数据。
>
> 子 词分词器（Subword Tokenizer）被广泛应用于基于 Transformer 的语言模型中，包 括 BPE 分词、WordPiece 分词和 Unigram 分词三种常见方法。

- BPE分词
  - 一 组基本符号（例如字母和边界字符）开始，迭代地寻找语料库中的两个相邻词元， 并将它们替换为新的词元，这一过程被称为合并。合并的选择标准是计算两个连 续词元的共现频率，也就是每次迭代中，最频繁出现的一对词元会被选择与合并。 合并过程将一直持续达到预定义的词表大小。
  - ![image-20240529100834975](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240529100834975.png)
- 字节级别的BPE
  - 将字节视为合并操作的基本符号
  - 即使是复杂的字符（如中文汉字）也可以被表示为一系列字节，这样就可以通过合并字节来形成更大的词元

- WordPiece分词
- Unigram分词

**分词器的选用**

> 最近的大语言模型通常使用 SentencePiece 代码库 [144] 为预训练语料训练定制化的分词器， 这一代码库支持字节级别的 BPE 分词和 Unigram 分词。

为了训练出高效的分词器，关注以下因素：

- 具备无损重构的特性
  - 分词结果能够准确无误地还原为原始输入文本
- 具有高压缩率
  - 在给定文本数据的情况下，经过分词处理后的词元数量应尽可能少
- 设计专门的分词器
  - 以 LLaMA 为例，主要包含英语文本的预训练语料训练了 BPE 分词器，在中文数据上分词器表现不佳
  - 针对数学能力可能需要对数字进行专门的分词器设计，例如，BPE 分词器可能将整数 7,481 分词为“7 481”，而将整数 74,815 分词为“748 15”。 这导致相同的数字被分割成不同的子串，降低了解决相关数学问题的能力

### 4.4 数据调度

设计合适的调度策略来安排这些多来源的数据

两个方面：各个数据源的混合比例以及各数据源用于训练的顺序（称为数据课程，Data Curriculum）

<img src="https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240529104302750.png" alt="image-20240529104302750" style="zoom: 50%;" />

#### 4.4.1 数据混合

常见LLM的数据配比情况：

![image-20240529105217305](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240529105217305.png)

- 上采样和下采样
  - 上采样
    - 增加少数类样本的数量来匹配多数类样本数量的过程。在数据集中，如果某个类别或数据源的样本数量较少，可以通过复制现有样本、生成新的合成样本（例如使用SMOTE算法），或者通过数据增强技术来增加该类别的样本数量。这样做可以减少或消除数据集的不平衡，使得模型不会过度偏向于多数类。
  - 下采样
    - 减少多数类样本的数量以匹配少数类样本数量的过程。在数据集中，如果某个类别或数据源的样本数量过多，可以通过随机选择少部分样本或使用更复杂的样本选择技术来减少该类别的样本数量。下采样有助于减轻模型训练时的计算负担，并减少因样本不平衡导致的偏差。

- 典型的数据分布
  - LLaMA [34] 的预训练数据主要包括超过 80% 的网页数据、来自 GitHub 和 StackExchange 的 6.5% 代码密集型数据、4.5% 的书籍数据，以及来 自 arXiv 的 2.5% 科学数据

- 数据混合策略
  - 增加数据源的多样性
    - 收集预训练数据时，需要注意引入数据多样性更高的数据源， 如包含网页数据、各类型书籍、代码数据等
  - 优化数据混合
    - 例如：通过在小型LM上实验不同的数据混合配比并测试性能，选取最好的配比方案再进行LLM训练
  - 优化特定能力
    - 通过增加特定数据源的比例来增强对应的模型能力

#### 4.4.2 数据课程

> 数据课程是指按照特定的顺序安排预训练数 据进行模型的训练。例如，从简单/通用的数据开始，逐渐引入更具挑战性/专业化的数据。更广泛地说，它可以指训练期间在**不同阶段**使用不同的数据源混合配比。
>
> 一种实用方法是基于专门构建的评测基准监控大语言模型的关键能力的学习过程，然后在预训练期间动态调整数据的混合配比。
>
> 目前针对数据课程的研究工作主要集中在继续预训练CPT（Continual Pre-training）。

> *CPT* 和 *SFT*:
>
> - **CPT（Continual Pre-training）**:
>   - CPT是指在模型的初始预训练完成之后，继续在新的数据集上进行额外的预训练。这通常是为了使模型适应特定领域或任务，或者整合新出现的数据。CPT的目的是在保持模型原有知识的同时，让模型学习到新的、特定领域的信息。在CPT过程中，模型不是针对特定的任务进行优化，而是在更广泛的数据上进行训练以增强其理解能力。
>   - 类比于一个人在学习的不同阶段持续接受教育。比如，一个人在完成基础教育后，可能会继续进入大学学习更深入的知识，然后可能还会进行研究生学习或者职业培训。在这个过程中，他们不断扩展和深化自己的知识库，但并没有专门准备某个特定的考试或职位。这就像模型通过CPT不断学习新的数据，扩展其理解能力和知识范围，而不是为了在某个特定任务上取得优异的成绩。
>
> - **SFT（Supervised Fine-tuning）**:
>   - SFT是指在预训练的基础上，将模型在特定任务的标注数据上进行进一步训练的过程。这个过程通常涉及到任务特定的优化目标，例如分类任务的交叉熵损失或序列标注任务的条件随机场（CRF）损失。SFT的目的是使模型在某个具体任务上表现得更好，通过监督学习调整模型参数以适应任务特定的数据。
>   - 类比于一个人为了通过特定的考试或者获得某个职位而进行的针对性学习或训练。比如，一个律师准备司法考试，会专门学习法律条文和案例，或者一个运动员为了参加奥运会而专门练习某个项目的技巧。在这个过程中，他们的学习和训练是有明确目标的，旨在提高在特定领域或任务中的表现。这就像模型在SFT过程中，通过在标注数据上的训练，专门调整其参数，以在特定的任务（如文本分类、情感分析等）上表现得更好。
>
> 区分CPT和SFT的关键在于训练的目的和使用的数据：
>
> - **CPT** 更侧重于在广泛的数据上继续训练，以提高模型的泛化能力和领域适应性，而不是专注于特定任务的性能。
> - **SFT** 则是在特定任务的标注数据上进行训练，目的是优化模型在这个任务上的表现。

三种常见技能：

- 代码能力
  - CodeLLaMA的数据课程：2T 通用词元（网页数据） → 500B 代码密集型词元
  - CodeLLaMA-Python：2T 通用词元 → 500B 代码 相关的词元 → 100B Python 代码相关的词元

- 数学能力
  - Llemma数据课程为：2T 通用词元 → 500B 代码相关的词元 → 50∼200B 数学相关的词元

- 长文本能力
  - CodeLLaMA数据课程为：2.5T 词元，4K 上下文 窗口 → 20B 词元，16K 上下文窗口
  - 使用这种训练序列长度由短到长的数据能够使模型获得较好的长文本建模能力

#### 4.4.3 预训练数据准备概述——YuLan

1. 数据收集
   - 网页（Common Crawl）、书籍（Book3和Gutenberg）
   - 增强特定任务的能力：数学 （Proof-Pile）、代码（GitHub）
2. 数据清洗
   - 启发式规则、质量过滤
   - 去重：MinHash
3. 数据调度
   - 小模型代理方法
   - 用50B数据训练出一个1.3B小模型，测试下游任务的效果确定数据比例
   - 控制变量法调整比例

## 第5章 模型架构

![image-20240529134453507](https://raw.githubusercontent.com/ZhangYiwei-SZU/Pic/main/image-20240529134453507.png)

## 5.1 Transformer 模型

> Transformer 是由 多层的多头自注意力（Multi-head Self-attention）模块堆叠而成的神经网络模型。原始的 Transformer 模型由编码器和解码器两个部分构成，而这两个部分实际上可以 独立使用，例如基于编码器架构的 BERT 模型 [13] 和解码器架构的 GPT 模型 [14]。
>
> 模型主要使用**解码器架构**。
>
> 本部分内容将首先介绍 Transformer 模型的基本组成，包括基础的输入、多头自注意力模块和前置网络层；接着分别介绍Transformer 模型中的编码器和解码器模块。

